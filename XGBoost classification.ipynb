{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e85b533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jo_wilder/__init__.py', 'jo_wilder/competition.cpython-37m-x86_64-linux-gnu.so', 'jo_wilder_310/__init__.py', 'jo_wilder_310/competition.cpython-310-x86_64-linux-gnu.so', 'sample_submission.csv', 'test.csv', 'train.csv', 'train_labels.csv']\n"
     ]
    }
   ],
   "source": [
    "#=========================================================================\n",
    "# load up the libraries\n",
    "#=========================================================================\n",
    "import pandas  as pd\n",
    "import numpy   as np\n",
    "import xgboost as xgb\n",
    "\n",
    "#=========================================================================\n",
    "# read in the data\n",
    "#=========================================================================\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "\n",
    "# Set the path to your ZIP file\n",
    "zip_path = r'C:/Users/alial/OneDrive/Desktop/LHL/applications of ml assignments/predict-student-performance-from-game-play.zip'\n",
    "\n",
    "# Open and inspect the ZIP file\n",
    "with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "    print(z.namelist())  # Lists files inside the ZIP to confirm the names\n",
    "\n",
    "    # Read train.csv from the ZIP\n",
    "    with z.open('train.csv') as f_train:\n",
    "        train_data = pd.read_csv(f_train, index_col=0)\n",
    "\n",
    "    # Read test.csv from the ZIP\n",
    "    with z.open('test.csv') as f_test:\n",
    "        test_data = pd.read_csv(f_test, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34f9bc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26296946, 20)\n",
      "          session_id  index  elapsed_time      event_name   name  level  page  \\\n",
      "0  20090312431273200      0             0  cutscene_click  basic      0   NaN   \n",
      "1  20090312431273200      1          1323    person_click  basic      0   NaN   \n",
      "2  20090312431273200      2           831    person_click  basic      0   NaN   \n",
      "3  20090312431273200      3          1147    person_click  basic      0   NaN   \n",
      "4  20090312431273200      4          1863    person_click  basic      0   NaN   \n",
      "\n",
      "   room_coor_x  room_coor_y  screen_coor_x  screen_coor_y  hover_duration  \\\n",
      "0  -413.991405  -159.314686          380.0          494.0             NaN   \n",
      "1  -413.991405  -159.314686          380.0          494.0             NaN   \n",
      "2  -413.991405  -159.314686          380.0          494.0             NaN   \n",
      "3  -413.991405  -159.314686          380.0          494.0             NaN   \n",
      "4  -412.991405  -159.314686          381.0          494.0             NaN   \n",
      "\n",
      "                            text    fqid                       room_fqid  \\\n",
      "0                      undefined   intro  tunic.historicalsociety.closet   \n",
      "1  Whatcha doing over there, Jo?  gramps  tunic.historicalsociety.closet   \n",
      "2         Just talking to Teddy.  gramps  tunic.historicalsociety.closet   \n",
      "3     I gotta run to my meeting!  gramps  tunic.historicalsociety.closet   \n",
      "4            Can I come, Gramps?  gramps  tunic.historicalsociety.closet   \n",
      "\n",
      "                                           text_fqid  fullscreen  hq  music  \\\n",
      "0               tunic.historicalsociety.closet.intro           0   0      1   \n",
      "1  tunic.historicalsociety.closet.gramps.intro_0_...           0   0      1   \n",
      "2  tunic.historicalsociety.closet.gramps.intro_0_...           0   0      1   \n",
      "3  tunic.historicalsociety.closet.gramps.intro_0_...           0   0      1   \n",
      "4  tunic.historicalsociety.closet.gramps.intro_0_...           0   0      1   \n",
      "\n",
      "  level_group  \n",
      "0         0-4  \n",
      "1         0-4  \n",
      "2         0-4  \n",
      "3         0-4  \n",
      "4         0-4  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "train_csv = r'C:/Users/alial/OneDrive\\Desktop/LHL/applications of ml assignments/train.csv'\n",
    "test_csv  = r'C:/Users/alial/OneDrive\\Desktop/LHL/applications of ml assignments/test.csv'\n",
    "\n",
    "# Load CSVs directly\n",
    "df_train = pd.read_csv(train_csv)\n",
    "df_test  = pd.read_csv(test_csv)\n",
    "\n",
    "# Preview to confirm\n",
    "print(df_train.shape)\n",
    "print(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c02643ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          session_id  index  elapsed_time      event_name   name  level  page  \\\n",
      "0  20090312431273200      0             0  cutscene_click  basic      0   NaN   \n",
      "1  20090312431273200      1          1323    person_click  basic      0   NaN   \n",
      "2  20090312431273200      2           831    person_click  basic      0   NaN   \n",
      "3  20090312431273200      3          1147    person_click  basic      0   NaN   \n",
      "4  20090312431273200      4          1863    person_click  basic      0   NaN   \n",
      "\n",
      "   room_coor_x  room_coor_y  screen_coor_x  screen_coor_y  hover_duration  \\\n",
      "0  -413.991405  -159.314686          380.0          494.0             NaN   \n",
      "1  -413.991405  -159.314686          380.0          494.0             NaN   \n",
      "2  -413.991405  -159.314686          380.0          494.0             NaN   \n",
      "3  -413.991405  -159.314686          380.0          494.0             NaN   \n",
      "4  -412.991405  -159.314686          381.0          494.0             NaN   \n",
      "\n",
      "                            text    fqid                       room_fqid  \\\n",
      "0                      undefined   intro  tunic.historicalsociety.closet   \n",
      "1  Whatcha doing over there, Jo?  gramps  tunic.historicalsociety.closet   \n",
      "2         Just talking to Teddy.  gramps  tunic.historicalsociety.closet   \n",
      "3     I gotta run to my meeting!  gramps  tunic.historicalsociety.closet   \n",
      "4            Can I come, Gramps?  gramps  tunic.historicalsociety.closet   \n",
      "\n",
      "                                           text_fqid  fullscreen  hq  music  \\\n",
      "0               tunic.historicalsociety.closet.intro           0   0      1   \n",
      "1  tunic.historicalsociety.closet.gramps.intro_0_...           0   0      1   \n",
      "2  tunic.historicalsociety.closet.gramps.intro_0_...           0   0      1   \n",
      "3  tunic.historicalsociety.closet.gramps.intro_0_...           0   0      1   \n",
      "4  tunic.historicalsociety.closet.gramps.intro_0_...           0   0      1   \n",
      "\n",
      "  level_group  \n",
      "0         0-4  \n",
      "1         0-4  \n",
      "2         0-4  \n",
      "3         0-4  \n",
      "4         0-4  \n",
      "Index(['session_id', 'index', 'elapsed_time', 'event_name', 'name', 'level',\n",
      "       'page', 'room_coor_x', 'room_coor_y', 'screen_coor_x', 'screen_coor_y',\n",
      "       'hover_duration', 'text', 'fqid', 'room_fqid', 'text_fqid',\n",
      "       'fullscreen', 'hq', 'music', 'level_group'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26296946 entries, 0 to 26296945\n",
      "Data columns (total 20 columns):\n",
      " #   Column          Dtype  \n",
      "---  ------          -----  \n",
      " 0   session_id      int64  \n",
      " 1   index           int64  \n",
      " 2   elapsed_time    int64  \n",
      " 3   event_name      object \n",
      " 4   name            object \n",
      " 5   level           int64  \n",
      " 6   page            float64\n",
      " 7   room_coor_x     float64\n",
      " 8   room_coor_y     float64\n",
      " 9   screen_coor_x   float64\n",
      " 10  screen_coor_y   float64\n",
      " 11  hover_duration  float64\n",
      " 12  text            object \n",
      " 13  fqid            object \n",
      " 14  room_fqid       object \n",
      " 15  text_fqid       object \n",
      " 16  fullscreen      int64  \n",
      " 17  hq              int64  \n",
      " 18  music           int64  \n",
      " 19  level_group     object \n",
      "dtypes: float64(6), int64(7), object(7)\n",
      "memory usage: 3.9+ GB\n",
      "None\n",
      "session_id               0\n",
      "index                    0\n",
      "elapsed_time             0\n",
      "event_name               0\n",
      "name                     0\n",
      "level                    0\n",
      "page              25732402\n",
      "room_coor_x        2073272\n",
      "room_coor_y        2073272\n",
      "screen_coor_x      2073272\n",
      "screen_coor_y      2073272\n",
      "hover_duration    24294702\n",
      "text              16679807\n",
      "fqid               8274415\n",
      "room_fqid                0\n",
      "text_fqid         16679702\n",
      "fullscreen               0\n",
      "hq                       0\n",
      "music                    0\n",
      "level_group              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_train.head())\n",
    "print(df_train.columns)\n",
    "print(df_train.info())\n",
    "print(df_train.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9cfa1f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step 1: Load datasets\n",
    "train_csv = 'C:/Users/alial/OneDrive/Desktop/LHL/applications of ml assignments/train.csv'\n",
    "test_csv  = r'C:/Users/alial/OneDrive/Desktop/LHL/applications of ml assignments/test.csv'\n",
    "labels_csv = r'C:/Users/alial/OneDrive/Desktop/LHL/applications of ml assignments/train_labels.csv'\n",
    "\n",
    "df_train = pd.read_csv(train_csv)\n",
    "df_test = pd.read_csv(test_csv)\n",
    "df_labels = pd.read_csv(labels_csv)\n",
    "\n",
    "# Step 2: Clean 'session_id' in df_labels by removing suffixes like '_q<number>'\n",
    "df_labels['session_id'] = df_labels['session_id'].str.replace(r'_q\\d+$', '', regex=True)\n",
    "\n",
    "# Step 3: Ensure 'session_id' columns are same type (string) in both dataframes\n",
    "df_train['session_id'] = df_train['session_id'].astype(str)\n",
    "df_labels['session_id'] = df_labels['session_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0e259710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of common session_ids after cleaning: 23562\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Find common session_ids between train and labels to avoid mismatches\n",
    "common_sessions = set(df_train['session_id']).intersection(set(df_labels['session_id']))\n",
    "print(f\"Number of common session_ids after cleaning: {len(common_sessions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "69eabef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 2000  # or smaller like 1000\n",
    "sample_sids = df_labels_reduced['session_id'].sample(sample_size, random_state=42).unique()\n",
    "\n",
    "df_train_sample = df_train[df_train['session_id'].isin(sample_sids)]\n",
    "df_labels_sample = df_labels_reduced[df_labels_reduced['session_id'].isin(sample_sids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7a34a116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example relevant columns from training data (adjust as needed)\n",
    "relevant_train_cols = ['session_id', 'elapsed_time', 'event_name', 'level', 'room_coor_x', 'room_coor_y']\n",
    "\n",
    "# From labels, probably just 'session_id' and the target 'correct'\n",
    "relevant_label_cols = ['session_id', 'correct']\n",
    "\n",
    "df_train_sample = df_train[df_train['session_id'].isin(sample_sids)][relevant_train_cols]\n",
    "df_labels_sample = df_labels_reduced[df_labels_reduced['session_id'].isin(sample_sids)][relevant_label_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9f659b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data shape: (38419182, 7)\n"
     ]
    }
   ],
   "source": [
    "df_train_merged = df_train_sample.merge(df_labels_sample, on='session_id', how='inner')\n",
    "print(f\"Merged data shape: {df_train_merged.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "be845d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_merged['event_name'] = df_train_merged['event_name'].astype('category')\n",
    "df_train_merged['level'] = df_train_merged['level'].astype('int8')\n",
    "df_train_merged['correct'] = df_train_merged['correct'].astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d791cb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns that won't be useful or cause issues (adjust as needed)\n",
    "cols_to_drop = ['session_id', 'text', 'page']  # example non-numeric or unstructured columns\n",
    "df = df_train_merged.drop(columns=[col for col in cols_to_drop if col in df_train_merged.columns])\n",
    "\n",
    "# Handle missing values for numeric columns (example: fill with 0)\n",
    "for col in df.select_dtypes(include=['float', 'int']).columns:\n",
    "    df[col] = df[col].fillna(0)\n",
    "\n",
    "# Convert categorical columns to numeric codes (if any)\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "for col in categorical_cols:\n",
    "    df[col] = df[col].astype('category').cat.codes\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = df.drop(columns=['correct'])\n",
    "y = df['correct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591eaab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "print(type(X))  # Is it sparse?\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c4f668",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Initialize model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a54267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "feature_importances = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "feature_importances.head(20).plot(kind='bar')\n",
    "plt.title('Top 20 Feature Importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23927ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_train = pd.DataFrame(X_train)\n",
    "df_X_train.to_csv(\"X_train.csv\", index=False)\n",
    "\n",
    "# Save y_train (if it's 1D, just convert directly)\n",
    "df_y_train = pd.DataFrame(y_train, columns=[\"target\"])\n",
    "df_y_train.to_csv(\"y_train.csv\", index=False)\n",
    "\n",
    "# Similarly for validation sets:\n",
    "pd.DataFrame(X_val).to_csv(\"X_val.csv\", index=False)\n",
    "pd.DataFrame(y_val, columns=[\"target\"]).to_csv(\"y_val.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
